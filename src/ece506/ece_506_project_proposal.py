# -*- coding: utf-8 -*-
"""ECE_506_Project_proposal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EYwaEerknrXl-5l_1Z4ujRjV1ux2tXjT
"""

import numpy as np
import cv2
import os
import random
import matplotlib.pyplot as plt
import kagglehub
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential,Model,load_model
from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Flatten,Dense,Activation,Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.preprocessing import image

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import GridSearchCV, train_test_split,RandomizedSearchCV,StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC,LinearSVC
from sklearn.metrics import accuracy_score, classification_report

import torch

# 1. Dataset download & paths
print("Downloading / locating RAF-DB dataset...")
base_path = kagglehub.dataset_download("shuvoalok/raf-db-dataset")
print("Path to dataset files:", base_path)

DATASET_FOLDER = os.path.join(base_path, "DATASET")
TRAIN_FOLDER = os.path.join(DATASET_FOLDER, "train")
TEST_FOLDER = os.path.join(DATASET_FOLDER, "test")

if not os.path.exists(TRAIN_FOLDER):
    raise RuntimeError(f"Train folder not found at {TRAIN_FOLDER}")
if not os.path.exists(TEST_FOLDER):
    raise RuntimeError(f"Test folder not found at {TEST_FOLDER}")

print("Train subfolders:", os.listdir(TRAIN_FOLDER))

# 2. Helpers
def find_class_folders(directory_path):
    if not os.path.isdir(directory_path):
        raise ValueError(f"'{directory_path}' is not a valid directory.")
    entries = os.listdir(directory_path)
    folders = [
        e for e in entries
        if os.path.isdir(os.path.join(directory_path, e))
    ]
    return folders

# Emotion map from numeric folder names
emotion_map = {
'1': 'Surprise',
'2': 'Fearful',
'3': 'Disgusted',
'4': 'Happy',
'5': 'Sad',
'6': 'Angry',
'7': 'Neutral'
}

def count_images_per_class(folder, emotion_map):
    counts = {}
    for class_id, class_name in emotion_map.items():
        class_folder = os.path.join(folder, class_id)
        if os.path.exists(class_folder):
            counts[class_name] = len(os.listdir(class_folder))
        else:
            counts[class_name] = 0
    return counts

# Count images in training and test sets
train_counts = count_images_per_class(TRAIN_FOLDER, emotion_map)
test_counts = count_images_per_class(TEST_FOLDER, emotion_map)

print("Training set counts:")
for cls, cnt in train_counts.items():
    print(f"{cls}: {cnt} images")

print("\nTest set counts:")
for cls, cnt in test_counts.items():
    print(f"{cls}: {cnt} images")



def load_dataset(folder_path, categories, img_size=100):
    data = []

    for folder in categories:
        folder_path_full = os.path.join(folder_path, folder)
        label = categories.index(folder)  # 0..6

        for fname in os.listdir(folder_path_full):
            if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
                continue
            fpath = os.path.join(folder_path_full, fname)
            img_arr = cv2.imread(fpath)
            if img_arr is None:
                continue
            img_arr = cv2.resize(img_arr, (img_size, img_size))
            img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
            data.append([img_arr, label])

    print(f"Total images loaded from {folder_path}: {len(data)}")
    random.shuffle(data)

    X = np.array([feat for feat, _ in data], dtype="float32") / 255.0
    Y = np.array([lbl for _, lbl in data], dtype="int64")

    return X, Y

# Load training data
X_train, Y_train = load_dataset(TRAIN_FOLDER, categories, img_size=100)
print("Training data shapes:", X_train.shape, Y_train.shape)

# 5-Fold Cross-Validation

# Number of folds
k = 5
skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)

# To store fold indices
folds = list(skf.split(X, Y))
print(f"Total samples: {X.shape[0]}, Number of folds: {k}")
print("First fold train/val sizes:", len(folds[0][0]), len(folds[0][1]))

# CNN Model
def create_model(input_shape=X.shape[1:]):
    model = Sequential([
        Input(shape=input_shape),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(7, activation='softmax')  # 7 classes
    ])

    model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy']
    )
    return model

# Train and validate model using 5-fold cross validation
histories = []
fold_no = 1

for train_idx, val_idx in folds:
    print(f"\nTraining fold {fold_no}...")

    # Split data for fold
    X_train_fold, X_val_fold = X[train_idx], X[val_idx]
    y_train_fold, y_val_fold = Y[train_idx], Y[val_idx]

    # Create a fresh CNN model
    model = create_model()

    # Callbacks
    checkpoint = ModelCheckpoint(
        f"fer_cnn_best_fold{fold_no}.keras",
        monitor="val_accuracy",
        mode="max",
        save_best_only=True,
        verbose=1
    )
    earlystop = EarlyStopping(
        monitor="val_accuracy",
        mode="max",
        min_delta=1e-4,
        patience=10,
        verbose=1,
        restore_best_weights=True
    )

    # Train the model
    history = model.fit(
        X_train_fold, y_train_fold,
        epochs=30,
        batch_size=64,
        validation_data=(X_val_fold, y_val_fold),
        callbacks=[checkpoint, earlystop],
        verbose=1
    )

    histories.append(history)
    fold_no += 1


val_acc_per_fold = [max(h.history['val_accuracy']) for h in histories]
print("\nValidation accuracy per fold:", val_acc_per_fold)
print("Average validation accuracy:", np.mean(val_acc_per_fold))

# Load test data
X_test, Y_test = load_dataset(TEST_FOLDER, categories, img_size=100)
print("Training data shapes:", X_test.shape, Y_test.shape)

test_accuracies = []

for fold_no in range(1, 6):  # 5 folds
    # Load the best model from each fold
    model_path = f"fer_cnn_best_fold{fold_no}.keras"
    print(f"\nEvaluating fold {fold_no} model on test set...")
    model = load_model(model_path)

    # Evaluate
    loss, acc = model.evaluate(X_test, Y_test, verbose=0)
    print(f"Fold {fold_no} Test Accuracy: {acc:.4f}")
    test_accuracies.append(acc)

# Average test accuracy across all folds
print("\nTest accuracy per fold:", test_accuracies)
print("Average test accuracy across folds:", np.mean(test_accuracies))

# Train and validate SVM
svm_accuracies = []

fold_no = 1
for train_idx, val_idx in folds:
    print(f"\nFold {fold_no}: CNN feature extraction for SVM...")

    # Split data for fold
    X_train_fold, X_val_fold = X[train_idx], X[val_idx]
    y_train_fold, y_val_fold = Y[train_idx], Y[val_idx]

    # Create fresh CNN model and train (or load pretrained best fold CNN)
    model = create_model()
    # Optional: load pretrained CNN weights for this fold
    model.load_weights(f"fer_cnn_best_fold{fold_no}.keras")

    # Extract features from second-to-last dense layer
    feature_extractor = Model(
        inputs=model.inputs,
        outputs=model.layers[-2].output
    )

    X_train_feats = feature_extractor.predict(X_train_fold)
    X_val_feats = feature_extractor.predict(X_val_fold)

    print("Feature shape:", X_train_feats.shape)

    # Train SVM on CNN features
    svm_clf = SVC(kernel='rbf', probability=True, class_weight='balanced')
    print("Training SVM on CNN features...")
    svm_clf.fit(X_train_feats, y_train_fold)

    # Validate
    y_val_pred_svm = svm_clf.predict(X_val_feats)
    svm_acc = accuracy_score(y_val_fold, y_val_pred_svm)
    print(f"SVM val accuracy (fold {fold_no}): {svm_acc:.4f}")

    svm_accuracies.append(svm_acc)
    fold_no += 1

print("\nAverage SVM validation accuracy across folds:", np.mean(svm_accuracies))

svm_test_accuracies = []

for fold_no in range(1, 6):  # 5 folds
    print(f"\nEvaluating SVM for fold {fold_no} on test set...")

    # Load CNN model for this fold
    cnn_model_path = f"fer_cnn_best_fold{fold_no}.keras"
    cnn_model = load_model(cnn_model_path)

    # Feature extractor from second-to-last Dense layer
    feature_extractor = Model(
        inputs=cnn_model.inputs,
        outputs=cnn_model.layers[-2].output
    )

    # Generate CNN features for this fold's training set
    train_idx, val_idx = folds[fold_no - 1]
    X_train_fold, y_train_fold = X[train_idx], Y[train_idx]
    X_train_feats = feature_extractor.predict(X_train_fold)

    # Generate CNN features for test set
    X_test_feats = feature_extractor.predict(X_test)

    # Train SVM on the fold's training features
    svm_clf = SVC(kernel='rbf', probability=True, class_weight='balanced')
    svm_clf.fit(X_train_feats, y_train_fold)

    # Evaluate SVM on independent test set
    y_test_pred_svm = svm_clf.predict(X_test_feats)
    test_acc = accuracy_score(Y_test, y_test_pred_svm)
    print(f"SVM test accuracy (fold {fold_no}): {test_acc:.4f}")

    svm_test_accuracies.append(test_acc)

# Average test accuracy across all folds
print("\nSVM Test Accuracy per fold:", svm_test_accuracies)
print("Average SVM Test Accuracy:", np.mean(svm_test_accuracies))

# 7. Ensemble with CNN + SVM

# Feature extractor for CNN probabilities
feature_extractor = Model(
    inputs=model.inputs,
    outputs=model.layers[-2].output
)

def ensemble_predict_proba(img_batch, alpha=0.5):
    """
    alpha: weight for CNN; (1-alpha) for SVM
    """
    # CNN probabilities
    cnn_proba = model.predict(img_batch, verbose=0)

    # SVM probabilities (convert decision_function to [0,1])
    # Flatten and scale raw images for SVM
    imgs_flat = img_batch.reshape(img_batch.shape[0], -1)
    imgs_scaled = scaler_svm.transform(imgs_flat)

    svm_scores = svm_clf.decision_function(imgs_scaled)
    svm_proba = MinMaxScaler().fit_transform(svm_scores)

    # Convex combination
    return alpha * cnn_proba + (1 - alpha) * svm_proba

def ensemble_predict_label(img_batch, alpha=0.5):
    proba = ensemble_predict_proba(img_batch, alpha)
    return np.argmax(proba, axis=1)

# 8. Find optimal alpha

alphas = np.linspace(0, 1, 11)  # 0.0, 0.1, ..., 1.0
best_acc = 0
best_alpha = 0.5

for a in alphas:
    y_val_pred = ensemble_predict_label(X_val, alpha=a)
    acc = accuracy_score(y_val, y_val_pred)
    print(f"alpha={a:.1f}, val accuracy={acc:.4f}")
    if acc > best_acc:
        best_acc = acc
        best_alpha = a

print(f"\nOptimal alpha: {best_alpha:.2f}, Validation Accuracy: {best_acc:.4f}")

# 9. Evaluate final ensemble

y_val_pred_ens = ensemble_predict_label(X_val, alpha=best_alpha)
print("\nClassification report for final ensemble:")
print(classification_report(y_val, y_val_pred_ens))

# 8. Demo on random test image
print("Running demo prediction on random TEST image...")

test_subfolders = [
    f for f in os.listdir(TEST_FOLDER)
    if os.path.isdir(os.path.join(TEST_FOLDER, f))
]

chosen_folder = random.choice(test_subfolders)
test_img_files = [
    f for f in os.listdir(os.path.join(TEST_FOLDER, chosen_folder))
    if f.lower().endswith((".jpg", ".jpeg", ".png"))
]

if not test_img_files:
    print("No test images found in chosen folder.")
else:
    chosen_img = random.choice(test_img_files)
    img_path = os.path.join(TEST_FOLDER, chosen_folder, chosen_img)
    print("Random image:", img_path)

    true_idx = int(chosen_folder) - 1  # folders are '1'..'7'
    true_label = emotion_map.get(chosen_folder, "Unknown")

    img_obj = image.load_img(img_path, target_size=(img_size, img_size))
    img_arr = image.img_to_array(img_obj) / 255.0
    img_batch = np.expand_dims(img_arr, axis=0)

    proba = ensemble_predict_proba(img_batch, alpha=0.5)
    pred_idx = int(np.argmax(proba, axis=1)[0])  # 0..6
    pred_folder = str(pred_idx + 1)
    pred_label = emotion_map.get(pred_folder, "Unknown")

    plt.imshow(img_obj)
    plt.title(f"Ensemble Pred: {pred_label}\nTrue: {true_label}")
    plt.axis("off")
    plt.show()

    print("Ensemble probabilities:", proba)
    print(f"Pred index: {pred_idx} ({pred_label})")
    print(f"True index: {true_idx} ({true_label})")